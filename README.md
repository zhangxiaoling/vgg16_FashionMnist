vgg16_FashionMnist
==================
深度迁移学习不同场景下的应用
-------------------------
•	场景一：数据集小，与预训练模型的训练数据相似度高

由于这种情况下数据与预训练模型的训练数据相似度很高，因此不需要重新训练模型，只需要将输出层改成符合问题情景下的结构。这里使用预处理模型作为模式提取器。

•	场景二：数据集小，与预训练模型的训练数据相似度不高

在这种情况下，可以冻结预训练模型中的前k个层中的权重，重新训练后面的n-k个层。由于数据相似度不高，重新训练的过程就变得十分关键。而新数据集大小的不足，通过冻结预训练模型的前k层进行弥补。

•	场景三：数据集大，与预训练模型的训练数据相似度不高

由于数据集较大，神经网络的训练过程会比较有效率。然而，因为实际数据和预训练模型的训练数据之间存在很大差异，采用预训练模型不是一种高效的方式。因此最好的方法是将预处理模型中的权重全部初始化后在新数据集的基础上重头开始训练。

•	场景四：数据集大，与预训练模型的训练数据相似度高

这是最理想的情况，采用预训练模型会变得非常高效。保持模型原有的结构和初始权重不变，在新数据集的基础上重新训练。


预训练结构VGG16和ImageNet
-------------------------------
预训练模型是前人为了解决类似问题所创造出来的模型。在解决问题时，不用从零开始训练一个新模型，可以从类似问题中训练过的模型入手。VGG16 是基于大量真实图像的 ImageNet 图像库预训练的深度卷积神经网络。VGG16作为基础网络，其分类性能非常好，网络结构非常规整，修改起来相对容易，在ImageNet上训练的模型也已经开源，可以在此基础上对其他数据集进行微调，对其他数据集适应能力很好，效果也很好。因此VGG16是深度迁移学习预训练模型的很好选择。

![](https://github.com/zhangxiaoling/vgg16_FashionMnist/blob/master/1.png)

实验结构和数据集
---------------------------------
Fashion-MNIST是Zalando文章的一个数据集，包括60,000个示例的训练集和10,000个示例的测试集。每个示例都是一个28x28灰度图像，分别来自10个标签。
![](https://github.com/zhangxiaoling/vgg16_FashionMnist/blob/master/3.png)

由于FashionMnist数据集偏小，所以这个问题应该属于上述场景中的场景一或场景二。由于数据集的标签与imagenet的相差较远，因此这里采用场景二的方法进行实验。即冻结预训练模型中的前4个层中的权重，重新训练后面的4个层。实验所采用的具体结构如下：

![](https://github.com/zhangxiaoling/vgg16_FashionMnist/blob/master/2.png)

实验环境
--------------------------------
keras、tensorflow、python、numpy等

步骤
---------------------------------
1、下载vgg16预训练的权重文件[weights_path_no_top]（https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5）

2、加载vgg16结构文件（已经过修改）

3、运行main_sgd_fashionmnist.py文件

结果
---------------------------------
Acc：92.90（epoch=500）
